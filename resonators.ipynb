{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "E6R7nSA6c8sf",
        "Ij79EHtaNDCt",
        "CUOAr6RddAdK"
      ],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prelude\n",
        "\n"
      ],
      "metadata": {
        "id": "uwIzSYF_iLxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Resonators**](https://github.com/0xmaddie/0xmaddie/blob/main/resonators)\n",
        "is a Python library that uses data races and particle swarm dynamics\n",
        "to approximate functions. You can train a resonator like a transformer\n",
        "but it uses Python objects instead of vectors.\n",
        "\n",
        "You can do program evolution with a stack of \"genetic transformer\" blocks each containing fitness, crossover, and mutation operations. attach weighted coins to race all of the operations and train this with a particle swarm on data showing the evolutionary paths you want.\n",
        "\n",
        "You can increase representational capacity by expressing conditional dependence between the weights. so per block there are F fitness weights, FxC crossover weights, FxCxM mutation weights representing the probaility that operation will be next in line during its race, along with 1 weight for a type of residual connection.\n",
        "\n",
        "The crossover operations combine several states in to one and the mutation operations transform one state in to several. This acts as a type of information bottleneck and provides an analogy to continuity in that it \"smooths out\" the details between states.\n"
      ],
      "metadata": {
        "id": "XBeyrgZNNEMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google\n",
        "google.colab.drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/secret.py .\n",
        "import secret"
      ],
      "metadata": {
        "id": "q-aQyEETzQUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "SjxzCm_80O4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login()"
      ],
      "metadata": {
        "id": "LOw4lMy6552G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction"
      ],
      "metadata": {
        "id": "7ry3CWWxMPCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "8OZwrT4Ij_9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import numpy\n",
        "import scipy\n",
        "from typing import Optional\n",
        "\n",
        "class DecoderError(Exception):\n",
        "  message: str\n",
        "  body: Optional[dict[str, object]]\n",
        "\n",
        "  def __init__(self, message, body=None):\n",
        "    self.message = message\n",
        "    self.body    = body\n",
        "\n",
        "  def __str__(self):\n",
        "    return self.message\n",
        "\n",
        "  @staticmethod\n",
        "  def no_fitness():\n",
        "    return DecoderError(f'No fitness operation available.')\n",
        "\n",
        "  @staticmethod\n",
        "  def no_crossover(fitness_id):\n",
        "    return DecoderError(f'No crossover operation available.')\n",
        "\n",
        "  @staticmethod\n",
        "  def no_mutation(fitness_id, crossover_id):\n",
        "    return DecoderError(f'No mutation operation available.')\n",
        "\n",
        "class Decoder:\n",
        "  fitness: list[callable]\n",
        "  crossover: list[callable]\n",
        "  mutation: list[callable]\n",
        "  weights: numpy.ndarray\n",
        "  state_capacity: int\n",
        "  state_bottleneck: int\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    fitness: list[callable],\n",
        "    crossover: list[callable],\n",
        "    mutation: list[callable],\n",
        "    weights: numpy.ndarray,\n",
        "    state_capacity: int,\n",
        "    state_bottleneck: int,\n",
        "  ):\n",
        "    self.fitness          = fitness\n",
        "    self.crossover        = crossover\n",
        "    self.mutation         = mutation\n",
        "    self.weights          = weights\n",
        "    self.state_capacity   = state_capacity\n",
        "    self.state_bottleneck = state_bottleneck\n",
        "\n",
        "    assert len(weights) == self.layers*self.weights_per_layer\n",
        "\n",
        "  @staticmethod\n",
        "  def num_weights_for_components(fitness, crossover, mutation, layers):\n",
        "    fitl   = len(fitness)\n",
        "    crossl = len(fitness)*len(crossover)\n",
        "    mutl   = len(fitness)*len(crossover)*len(mutation)\n",
        "    return layers*(fitl+crossl+mutl+1)\n",
        "\n",
        "  @property\n",
        "  def weights_per_layer(self):\n",
        "    return self.fitness_weights_per_layer+self.crossover_weights_per_layer+self.mutation_weights_per_layer+1\n",
        "\n",
        "  @property\n",
        "  def layers(self):\n",
        "    return len(self.weights)//self.weights_per_layer\n",
        "\n",
        "  @property\n",
        "  def fitness_weights_per_layer(self):\n",
        "    return len(self.fitness)\n",
        "\n",
        "  @property\n",
        "  def crossover_weights_per_layer(self):\n",
        "    return len(self.fitness)*len(self.crossover)\n",
        "\n",
        "  @property\n",
        "  def mutation_weights_per_layer(self):\n",
        "    return len(self.fitness)*len(self.crossover)*len(self.mutation)\n",
        "\n",
        "  def fitness_weights(self, layer):\n",
        "    lhs = layer*self.weights_per_layer\n",
        "    return self.weights[lhs:lhs+self.fitness_weights_per_layer]\n",
        "\n",
        "  def crossover_weights(self, layer, fitness):\n",
        "    lhs = layer*self.weights_per_layer+self.fitness_weights_per_layer\n",
        "    return self.weights[lhs:lhs+self.crossover_weights_per_layer]\n",
        "\n",
        "  def mutation_weights(self, layer, fitness, crossover):\n",
        "    lhs = layer*self.weights_per_layer+self.fitness_weights_per_layer+self.crossover_weights_per_layer\n",
        "    return self.weights[lhs:lhs+self.mutation_weights_per_layer]\n",
        "\n",
        "  def residual_weights(self, layer):\n",
        "    lhs = layer*self.weights_per_layer+self.fitness_weights_per_layer+self.crossover_weights_per_layer+1\n",
        "    return self.weights[lhs]\n",
        "\n",
        "  def race(self, components, weights):\n",
        "    sorted_components = numpy.random.choice(\n",
        "      components,\n",
        "      size=len(components),\n",
        "      replace=False,\n",
        "      p=self.__softmax(weights),\n",
        "    )\n",
        "    return sorted_components\n",
        "\n",
        "  def __softmax(self, array):\n",
        "    return scipy.special.softmax(array)\n",
        "\n",
        "  def __coin(self, weight):\n",
        "    return numpy.random.random() < weight\n",
        "\n",
        "  def __choice(self, components):\n",
        "    return numpy.random.choice(components)\n",
        "\n",
        "  def __call__(self, states):\n",
        "    for layer in range(self.layers):\n",
        "      hidden_states = []\n",
        "      for i in range(self.state_capacity):\n",
        "        sorted_fitness = self.race(\n",
        "          self.fitness,\n",
        "          self.fitness_weights(layer),\n",
        "        )\n",
        "        fitness_hidden      = []\n",
        "        current_fitness_id  = 0\n",
        "        selected_fitness_id = None\n",
        "        while selected_fitness_id is None and current_fitness_id < len(self.fitness):\n",
        "          local_fitness = sorted_fitness[current_fitness_id]\n",
        "          fitness_hidden.clear()\n",
        "          for state in states:\n",
        "            if local_fitness(state):\n",
        "              print(f'Decoder current_fitness_id {current_fitness_id} {state} True')\n",
        "              fitness_hidden.append(state)\n",
        "              if len(fitness_hidden) >= self.state_bottleneck:\n",
        "                selected_fitness_id = current_fitness_id\n",
        "                break\n",
        "            else:\n",
        "              print(f'Decoder current_fitness_id {current_fitness_id} {state} False')\n",
        "          current_fitness_id += 1\n",
        "        if selected_fitness_id is None:\n",
        "          raise DecoderError.no_fitness(states)\n",
        "        assert len(fitness_hidden) == self.state_botteneck\n",
        "        print(f'Decoder.fitness_hidden = {fitness_hidden} Ok')\n",
        "        sorted_crossover = self.race(\n",
        "          self.crossover,\n",
        "          self.crossover_weights(layer, selected_fitness_id),\n",
        "        )\n",
        "        crossover_hidden      = None\n",
        "        current_crossover_id  = 0\n",
        "        selected_crossover_id = None\n",
        "        while selected_crossover_id is None and current_crossover_id < len(self.crossover):\n",
        "          local_crossover = sorted_crossover[current_crossover_id]\n",
        "          try:\n",
        "            crossover_hidden      = functools.reduce(local_crossover, fitness_hidden)\n",
        "            selected_crossover_id = current_crossover_id\n",
        "          except DecoderError as err:\n",
        "            print(f'Decoder.current_crossover_id {current_crossover_id} Err')\n",
        "            current_crossover_id += 1\n",
        "        if selected_crossover_id is None:\n",
        "          raise DecoderError.no_crossover(states, selected_fitness_id)\n",
        "        assert crossover_hidden is not None\n",
        "        print(f'Decoder.crossover_hidden = {crossover_hidden} Ok')\n",
        "        sorted_mutation = self.race(\n",
        "          self.mutation,\n",
        "          self.mutation_weights(layer, selected_fitness_id, selected_crossover_id)\n",
        "        )\n",
        "        mutation_hidden      = []\n",
        "        current_mutation_id  = 0\n",
        "        selected_mutation_id = None\n",
        "        while selected_mutation_id is None and current_mutation_id < len(self.mutation):\n",
        "          local_mutation = sorted_mutation[current_mutation_id]\n",
        "          try:\n",
        "            mutation_hidden.clear()\n",
        "            for j in range(self.state_bottleneck):\n",
        "              point = local_mutation(crossover_hidden)\n",
        "              mutation_hidden.append(point)\n",
        "            selected_mutation_id = current_mutation_id\n",
        "          except DecoderError as err:\n",
        "            print(f'Decoder.current_mutation_id {current_mutation_id} Err')\n",
        "            current_mutation_id += 1\n",
        "        if selected_mutation_id is None:\n",
        "          raise DecoderError.no_mutation(states, selected_fitness_id, selected_crossover_id)\n",
        "        assert len(mutation_hidden) == self.state_bottleneck\n",
        "        print(f'Decoder.mutation_hidden {mutation_hidden}')\n",
        "        hidden_states += mutation_hidden\n",
        "      target_states = []\n",
        "      residual      = self.residual_weights(layer)\n",
        "      for i in range(self.state_capacity):\n",
        "        if self.__coin() < residual:\n",
        "          state = self.__choice(states)\n",
        "          print(f'Decoder residual state {state}')\n",
        "        else:\n",
        "          state = self.__choice(hidden_states)\n",
        "          print(f'Decoder hidden state {state}')\n",
        "        target_states.append(state)\n",
        "      print(f'Decoder.target_states {target_states}')\n",
        "      states = target_states\n",
        "    return states"
      ],
      "metadata": {
        "id": "K64jBS0IZfV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "class Llama:\n",
        "  tokenizer: transformers.AutoTokenizer\n",
        "  model: transformers.AutoModelForCausalLM\n",
        "  system_prompt: str\n",
        "  temperature: float\n",
        "  max_new_tokens: int\n",
        "  terminators: list\n",
        "  purity: int\n",
        "  quota: int\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    system_prompt: str = 'You are a helpful assistant.',\n",
        "    temperature: float = 0.7,\n",
        "    max_new_tokens: int = 4096,\n",
        "    purity: int = 100,\n",
        "    quota: int = 1000,\n",
        "    tokenizer = None,\n",
        "    model = None,\n",
        "  ):\n",
        "    model_name = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
        "    self.tokenizer = tokenizer or transformers.AutoTokenizer.from_pretrained(\n",
        "      model_name,\n",
        "      #cache_dir=secret.home,\n",
        "      #local_files_only=True,\n",
        "    )\n",
        "    self.model = model or transformers.AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      device_map='auto',\n",
        "      load_in_8bit=True,\n",
        "      #cache_dir=secret.home,\n",
        "      #local_files_only=True,\n",
        "    )\n",
        "    self.terminators = [\n",
        "      self.tokenizer.eos_token_id,\n",
        "      self.tokenizer.convert_tokens_to_ids('<|eot_id|>')\n",
        "    ]\n",
        "    self.system_prompt  = system_prompt\n",
        "    self.temperature    = temperature\n",
        "    self.max_new_tokens = max_new_tokens\n",
        "    self.purity         = purity\n",
        "    self.quota          = quota\n",
        "\n",
        "  def __apply_chat_template(self, state):\n",
        "    prompt = [{ 'role': 'system', 'content': self.system_prompt }]\n",
        "    for index, content in enumerate(state):\n",
        "      if index%2 == 0:\n",
        "        role = 'user'\n",
        "      else:\n",
        "        role = 'assistant'\n",
        "      prompt.append({ 'role': role, 'content': content })\n",
        "    print(f'Llama.prompt={prompt}')\n",
        "    input_ids = self.tokenizer.apply_chat_template(\n",
        "      prompt,\n",
        "      #tokenize=True,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors='pt',\n",
        "    ).to(self.model.device)\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "  def get(self, state):\n",
        "    source_ids = self.__apply_chat_template(state)\n",
        "    targets    = self.model.generate(\n",
        "      source_ids,\n",
        "      max_new_tokens=self.max_new_tokens,\n",
        "      do_sample=True,\n",
        "      temperature=self.temperature,\n",
        "      eos_token_id=self.terminators,\n",
        "    )\n",
        "    target_ids = targets[0][source_ids.shape[-1]:]\n",
        "    target     = self.tokenizer.decode(target_ids, skip_special_tokens=True)\n",
        "    print(f'Llama.get target={target}')\n",
        "    return target\n",
        "\n",
        "  def reduce(self, input, map, reduce):\n",
        "    quota   = self.quota\n",
        "    samples = []\n",
        "    while quota > 0 and len(samples) < self.purity:\n",
        "      quota -= 1\n",
        "      samples.clear()\n",
        "      try:\n",
        "        value = map(self.get(input))\n",
        "        print(f'Llama.reduce value={value}')\n",
        "        samples.append(value)\n",
        "      except ValueError:\n",
        "        pass\n",
        "    if len(samples) < self.purity and quota == 0:\n",
        "      raise ValueError(f'Llama.reduce quota consumed')\n",
        "    output = reduce(samples)\n",
        "    return output"
      ],
      "metadata": {
        "id": "94e8XmihvlVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model     = llm.model\n",
        "_tokenizer = llm.tokenizer"
      ],
      "metadata": {
        "id": "U-kW8DGdAZJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "  system_prompt=f'''\n",
        "You are a helpful assistant.\n",
        "'''.strip(),\n",
        "  temperature=0.7,\n",
        "  max_new_tokens=1024,\n",
        "  purity=1,\n",
        "  quota=3,\n",
        "  #model=_model,\n",
        "  #tokenizer=_tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "8gcxnxAolx6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_tag_body(document, tag_name):\n",
        "  # Perform string replacement to transform <value> tags into <div class=\"value\">\n",
        "  document = document.replace(f\"<{tag_name}>\", f'<div class=\"{tag_name}\">').replace(f\"</{tag_name}>\", \"</div>\")\n",
        "  # Parse the modified HTML document with BeautifulSoup\n",
        "  soup = BeautifulSoup(document, 'html.parser')\n",
        "  # Find all divs with the class \"value\"\n",
        "  value_divs = soup.find_all('div', class_=tag_name)\n",
        "  # Ensure there is exactly one div with class \"value\"\n",
        "  if len(value_divs) != 1:\n",
        "    raise ValueError(f\"Expected exactly one <div class='{tag_name}'> tag, but found {len(value_divs)}.\")\n",
        "  # Return the text content of the <div class=\"value\">\n",
        "  return value_divs[0].get_text()\n",
        "\n",
        "class Repository:\n",
        "  llm: Llama\n",
        "\n",
        "  def __init__(self, llm):\n",
        "    self.llm = llm\n",
        "\n",
        "  def get_fitness(self, operation):\n",
        "    def map_state(state):\n",
        "      value = get_tag_body(state, 'value')\n",
        "      match value:\n",
        "        case 'True':\n",
        "          return 1\n",
        "        case 'False':\n",
        "          return 0\n",
        "        case _:\n",
        "          raise ValueError(f'Expected a bool, but got {state}')\n",
        "      return value\n",
        "    def reduce_states(states):\n",
        "      average = sum(states)/len(states)\n",
        "      return average > 0.5\n",
        "    def hidden(state):\n",
        "      prompt = f'''\n",
        "Consider the following generative text-to-image prompt:\n",
        "\n",
        "<prompt>{state}</prompt>\n",
        "\n",
        "{operation} Think carefully, then respond with either True or False\n",
        "within <value></value> tags.\n",
        "'''.strip()\n",
        "      target = self.llm.reduce([prompt], map_state, reduce_states)\n",
        "      return target\n",
        "    return hidden\n",
        "\n",
        "  def get_crossover(self, operation):\n",
        "    def map_state(state):\n",
        "      prompt = get_tag_body(state, 'prompt')\n",
        "      return prompt\n",
        "    def reduce_states(states):\n",
        "      return states[0]\n",
        "    def hidden(fst, snd):\n",
        "      prompt = f'''\n",
        "Consider these two generative text-to-image prompts:\n",
        "\n",
        "<prompt>{fst}</prompt>\n",
        "<prompt>{snd}</prompt>\n",
        "\n",
        "{operation} Think carefully, then respond with the final\n",
        "prompt within <prompt></prompt> tags.\n",
        "'''.strip()\n",
        "      target = self.llm.reduce([prompt], map_state, reduce_states)\n",
        "      return target\n",
        "    return hidden\n",
        "\n",
        "  def get_mutation(self, operation):\n",
        "    def map_state(state):\n",
        "      prompt = get_tag_body(state, 'prompt')\n",
        "      return prompt\n",
        "    def reduce_states(states):\n",
        "      return states[0]\n",
        "    def hidden(state):\n",
        "      prompt = f'''\n",
        "Consider the following generative text-to-image prompt:\n",
        "\n",
        "<prompt>{state}</prompt>\n",
        "\n",
        "{operation} Think carefully, then respond with the final\n",
        "prompt within <prompt></prompt> tags.\n",
        "'''.strip()\n",
        "      target = self.llm.reduce([prompt], map_state, reduce_states)\n",
        "      return target\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "BH-kHssBly7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = Repository(llm)\n",
        "\n",
        "fitness = [\n",
        "  repo.fitness('Does this prompt mention anything related to anime?'),\n",
        "  repo.fitness('Does this prompt mention any famous artists?'),\n",
        "  repo.fitness('Does this prompt mention a famous location?'),\n",
        "  repo.fitness('Does this prompt mention flowers?'),\n",
        "  repo.fitness('Does this prompt mention animals?'),\n",
        "  repo.fitness('Would this prompt be popular on Reddit?'),\n",
        "  repo.fitness('Do you think images generated by this prompt would have people in them?'),\n",
        "  repo.fitness('Do you think images generated by this prompt would have animals in them?'),\n",
        "  repo.fitness('Does this prompt mention any specific historical art styles?'),\n",
        "  repo.fitness('Does this prompt include a famous artist from before 1912?'),\n",
        "  repo.fitness('Does this prompt involve a modern artist or art movement?'),\n",
        "  repo.fitness('Does this prompt specify an artistic medium, like oil painting or sculpture?'),\n",
        "  repo.fitness('Does this prompt mention a specific time period for the art style?'),\n",
        "  repo.fitness('Does this prompt refer to a well-known historical event?'),\n",
        "  repo.fitness('Does this prompt mention a specific location known for its artistic heritage?'),\n",
        "  repo.fitness('Does this prompt involve mythological figures or stories?'),\n",
        "  repo.fitness('Does this prompt feature any fictional characters?'),\n",
        "  repo.fitness('Does this prompt mention specific colors that should dominate the artwork?'),\n",
        "  repo.fitness('Does this prompt include specific elements of nature like mountains or rivers?'),\n",
        "  repo.fitness('Does this prompt mention urban settings or cityscapes?'),\n",
        "  repo.fitness('Does this prompt feature musical elements or musicians?'),\n",
        "  repo.fitness('Does this prompt include elements that are surreal or abstract?'),\n",
        "  repo.fitness('Does this prompt reference specific cultural symbols or national heritage?'),\n",
        "  repo.fitness('Is the prompt likely to generate interest among art historians?'),\n",
        "  repo.fitness('Does this prompt mention elements that would appeal to children?'),\n",
        "  repo.fitness('Does this prompt specify a mood or atmosphere, like melancholy or joy?'),\n",
        "  repo.fitness('Does this prompt suggest a narrative or scene with action?'),\n",
        "  repo.fitness('Does this prompt include technological elements or futuristic themes?'),\n",
        "  repo.fitness('Does this prompt have potential educational value?'),\n",
        "  repo.fitness('Would images generated from this prompt likely be controversial?'),\n",
        "  repo.fitness('Is the imagery likely to be peaceful or calming?'),\n",
        "  repo.fitness('Would this prompt be considered unique or rare?'),\n",
        "  repo.fitness('Does this prompt involve seasonal themes like winter or autumn?'),\n",
        "  repo.fitness('Does this prompt involve water elements like oceans or lakes?'),\n",
        "  repo.fitness('Does this prompt encourage exploring dark or horror themes?'),\n",
        "  repo.fitness('Does this prompt involve celestial elements like stars or planets?'),\n",
        "  repo.fitness('Is this prompt likely to engage amateur artists?'),\n",
        "  repo.fitness('Does this prompt involve famous fictional stories or books?')\n",
        "]\n",
        "\n",
        "crossover = [\n",
        "  repo.crossover('Combine these prompts in the most natural way possible.'),\n",
        "  repo.crossover('Combine these prompts in a surprising way.'),\n",
        "  repo.crossover('Think of another prompt that is a logical consequence of these prompts.'),\n",
        "  repo.crossover('Combine these prompts to create a harmonious blend of their themes.'),\n",
        "  repo.crossover('Merge these prompts while emphasizing any historical elements present in both.'),\n",
        "  repo.crossover('Create a new prompt that juxtaposes the primary subjects of these prompts in an unexpected way.'),\n",
        "  repo.crossover('Integrate the artistic styles mentioned in these prompts to form a new hybrid style.'),\n",
        "  repo.crossover('Combine these prompts in a way that tells a story or creates a narrative.'),\n",
        "  repo.crossover('Fuse these prompts while focusing on a dominant element from each.'),\n",
        "  repo.crossover('Combine these prompts to highlight contrast, such as modern versus ancient or natural versus man-made.'),\n",
        "  repo.crossover('Synthesize these prompts into a single prompt that would appeal to a specific audience or age group.'),\n",
        "  repo.crossover('Create a crossover that results in an artwork focusing on the interaction of elements from each prompt.'),\n",
        "  repo.crossover('Develop a prompt that would result in an artwork featuring a clash of the cultures or themes mentioned.'),\n",
        "  repo.crossover('Construct a new prompt that would feature elements of fantasy or surrealism from the original prompts.'),\n",
        "  repo.crossover('Merge these prompts to enhance the visual complexity of the resulting image.'),\n",
        "  repo.crossover('Combine these prompts to emphasize environmental or natural elements present in both.'),\n",
        "  repo.crossover('Formulate a new prompt that integrates the emotional or atmospheric tones of both prompts.'),\n",
        "  repo.crossover('Design a crossover that results in an educational or informative artwork combining elements of both prompts.'),\n",
        "  repo.crossover('Create a prompt that combines technological and historical themes from the original prompts.'),\n",
        "  repo.crossover('Construct a prompt that merges the specific locations mentioned in the original prompts into a single scene.'),\n",
        "  repo.crossover('Combine these prompts to create an artwork that could serve as a metaphor or allegory.'),\n",
        "  repo.crossover('Synthesize these prompts in a way that would result in an abstract or minimalistic artwork.'),\n",
        "  repo.crossover('Develop a prompt that balances elements of action and calm from the original prompts.')\n",
        "]\n",
        "\n",
        "mutation = [\n",
        "  repo.mutation('Make the theme of this prompt anime.'),\n",
        "  repo.mutation('Shorten this prompt to the absolute bare minimum while keeping the same meaning.'),\n",
        "  repo.mutation('Make the theme of this prompt ancient Greece.'),\n",
        "  repo.mutation('Make the theme of this prompt ancient Rome.'),\n",
        "  repo.mutation('Reinterpret this prompt as an oil painting.'),\n",
        "  repo.mutation('Reinterpret this prompt as a watercolor painting.'),\n",
        "  repo.mutation('Reinterpret this prompt as experimental photography.'),\n",
        "  repo.mutation('Transform this prompt into a futuristic or sci-fi theme.'),\n",
        "  repo.mutation('Convert this prompt into a children’s book illustration style.'),\n",
        "  repo.mutation('Adapt this prompt to the style of a famous artist not previously mentioned.'),\n",
        "  repo.mutation('Modify this prompt to include surreal or abstract elements.'),\n",
        "  repo.mutation('Change this prompt to focus on a specific season like winter or summer.'),\n",
        "  repo.mutation('Expand this prompt to include a detailed background setting.'),\n",
        "  repo.mutation('Alter this prompt to include a specific animal or creature.'),\n",
        "  repo.mutation('Make this prompt evoke a specific emotion like joy or sadness.'),\n",
        "  repo.mutation('Add a mythical or legendary component to this prompt.'),\n",
        "  repo.mutation('Shift this prompt’s setting from day to night.'),\n",
        "  repo.mutation('Enhance this prompt with a focus on dynamic movement or action.'),\n",
        "  repo.mutation('Incorporate a moral or philosophical question into this prompt.'),\n",
        "  repo.mutation('Adjust this prompt to emphasize architectural elements.')\n",
        "]"
      ],
      "metadata": {
        "id": "4pYBrFt6hAqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_states = [\n",
        "  \"A digital painting of a bustling cityscape in the Renaissance era, bustling with traders and artists.\",\n",
        "  \"A charcoal drawing of a serene garden filled with various types of flowers and butterflies.\",\n",
        "  \"A surrealistic scene featuring mythical creatures interacting in a futuristic urban setting.\",\n",
        "  \"An abstract oil painting depicting the emotional intensity of a violin player in a dimly lit room.\",\n",
        "  \"A watercolor painting of a quiet village by the sea during the golden hour, reflecting soft, warm lights.\",\n",
        "  \"A graphite sketch of famous landmarks from ancient Rome, including the Colosseum and Roman Forum.\",\n",
        "  \"A series of experimental photographs capturing the bustling nightlife of Tokyo.\",\n",
        "  \"A large-scale mural design incorporating elements of Native American folklore and landscape.\",\n",
        "  \"An ink drawing of a medieval battle scene, illustrating detailed armor and weaponry of the era.\",\n",
        "  \"A digital collage representing a fusion of various modern art styles seen in New York’s contemporary galleries.\",\n",
        "  \"A minimalist pastel drawing of a snowy landscape with subtle hints of wildlife presence.\",\n",
        "  \"A vibrant anime-style poster featuring a heroic character poised in a dynamic action pose.\",\n",
        "  \"A classical portrait of a famous historical figure from the Enlightenment period in a detailed study room.\",\n",
        "  \"An experimental mixed media piece that combines classical Greek sculpture with modern abstract forms.\",\n",
        "  \"A Victorian-era street scene depicted in the style of Impressionism, focusing on light and shadow effects.\"\n",
        "]\n",
        "initial_states = numpy.random.permutation(initial_state)\n",
        "layers         = 1\n",
        "num_weights    = Decoder.num_weights_for_components(fitness, crossover, mutation, layers)\n",
        "decoder        = Decoder(\n",
        "  fitness=fitness,\n",
        "  crossover=crossover,\n",
        "  mutation=mutation,\n",
        "  weights=numpy.random.random(num_weights),\n",
        "  state_capacity=len(initial_states),\n",
        "  state_bottleneck=2,\n",
        ")\n",
        "final_states = decoder(initial_states)\n",
        "print(final_states)"
      ],
      "metadata": {
        "id": "VrTXkFINx4yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning"
      ],
      "metadata": {
        "id": "CUOAr6RddAdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass(frozen=True)\n",
        "class Optimizer:\n",
        "  facc: float\n",
        "  fres: float\n",
        "  rate: float\n",
        "  decay: float\n",
        "\n",
        "  def __call__(self, pos, acc, grad):\n",
        "    hacc  = self.interp(grad, acc, self.facc)\n",
        "    res   = self.interp(grad, acc, self.fres)\n",
        "    mix   = pos*self.decay+sign(res)\n",
        "    delta = mix*self.rate\n",
        "    return delta, hacc\n",
        "\n",
        "class Tuner:\n",
        "  quota: int\n",
        "  purity: int\n",
        "  density: int\n",
        "  update: callable\n",
        "\n",
        "  def measure(self, machine, data):\n",
        "    energy = 0\n",
        "    for i in range(self.purity):\n",
        "      (init, eval)  = data()\n",
        "      energy       += eval(machine(init))\n",
        "    return energy/self.purity\n",
        "\n",
        "  def __call__(self, init, cons, data):\n",
        "    pos  = []\n",
        "    acc  = []\n",
        "    loss = []\n",
        "    for _ in range(self.quota):\n",
        "      for i in range(self.density):\n",
        "        machine = cons(pos[i])\n",
        "        loss[i] = self.measure(machine, data)\n",
        "      center  = self.average(pos, loss)\n",
        "      teacher = cons(center)\n",
        "      cutoff  = self.measure(teacher, data)\n",
        "      for i in range(self.density):\n",
        "        if loss[i] <= cutoff:\n",
        "          continue\n",
        "        compass  = pos[i]-center\n",
        "        sort     = compass*self.coherence\n",
        "        search   = (compass@compass)*self.noise()\n",
        "        gradient = sort+search\n",
        "        vel, acc = self.update(pos[i], acc[i], gradient)\n",
        "        pos[i]  += vel\n",
        "        acc[i]   = acc\n",
        "    return self.average(pos, loss)"
      ],
      "metadata": {
        "id": "BOHgnO8ib_3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Junk"
      ],
      "metadata": {
        "id": "wsbmJgfKj27L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "class Decoder:\n",
        "  def __init__(self, inputs, outputs, weights, purity=100, width=12, threshold=4):\n",
        "    self.inputs    = inputs\n",
        "    self.outputs   = outputs\n",
        "    self.weights   = weights\n",
        "    self.purity    = purity\n",
        "    self.width     = width\n",
        "    self.threshold = threshold\n",
        "\n",
        "  @property\n",
        "  def density(self):\n",
        "    return len(self.inputs)*len(self.outputs)\n",
        "\n",
        "  # The number of weights per layer.\n",
        "  @property\n",
        "  def layer_capacity(self):\n",
        "    return len(self.inputs) + len(self.inputs) * len(self.outputs) + 1\n",
        "\n",
        "  @property\n",
        "  def layers(self):\n",
        "    return len(self.weights)//self.layer_capacity\n",
        "\n",
        "  @property\n",
        "  def capacity(self):\n",
        "    return len(self.weights)\n",
        "\n",
        "  # The weights associated with the inputs for a certain layer.\n",
        "  def win(self, layer):\n",
        "    lhs = layer * self.capacity\n",
        "    return self.weights[lhs:lhs+len(self.inputs)]\n",
        "\n",
        "  # The weights associated with the outputs for a certain layer.\n",
        "  def wout(self, layer, input_index):\n",
        "    input_lhs  = layer * self.capacity\n",
        "    output_lhs = input_lhs + len(self.inputs)\n",
        "    target_lhs = output_lhs + input_index * len(self.outputs)\n",
        "    return self.weights[target_lhs:target_lhs+len(self.outputs)]\n",
        "\n",
        "  # The weights associated with the residual for a certain layer.\n",
        "  def wres(self, layer):\n",
        "    input_lhs    = layer * self.capacity\n",
        "    residual_idx = input_lhs + len(self.inputs) + len(self.inputs) * len(self.outputs)\n",
        "    return self.weights[residual_idx]\n",
        "\n",
        "  def sort(self, components, weights):\n",
        "    # Each weight is the probability that the corresponding\n",
        "    # component will be next in line.\n",
        "    indices = np.random.choice(\n",
        "      len(self.inputs),\n",
        "      size=len(self.inputs),\n",
        "      replace=False,\n",
        "      p=scipy.special.softmax(weights),\n",
        "    )\n",
        "    return indices\n",
        "\n",
        "  def __call__(self, swarm):\n",
        "    for time in range(self.layers):\n",
        "      inputw    = self.win(time)\n",
        "      residualw = self.wres(time)\n",
        "      hidden    = []\n",
        "      for i in range(self.purity):\n",
        "        print(f'Decoder.__call__ iteration # {i}')\n",
        "        # The inputs race to provide a measurement.\n",
        "        sample = []\n",
        "        inputbest = None\n",
        "        inputlist = self.sort(self.inputs, inputw)\n",
        "        inputlist = list(reversed(inputlist))\n",
        "        while inputbest is None and len(inputlist) > 0:\n",
        "          inputid = inputlist.pop()\n",
        "          input = self.inputs[inputid]\n",
        "          sample.clear()\n",
        "          for state in swarm:\n",
        "            if input(state):\n",
        "              print(f'Decoder.__call__ inputid={inputid} {state} True')\n",
        "              sample.append(state)\n",
        "            else:\n",
        "              print(f'Decoder.__call__ inputid={inputid} {state} False')\n",
        "            if len(sample) >= self.threshold:\n",
        "              inputbest = inputid\n",
        "              break\n",
        "        # If no inputs were able to provide a large enough measurement\n",
        "        # then an exception is raised.\n",
        "        if inputbest is None:\n",
        "          print(f'Decoder.__call__ inputid={inputid} Err')\n",
        "          raise ValueError()\n",
        "        assert len(sample) == self.threshold\n",
        "        print(f'Decoder.__call__ inputbest={inputbest} Ok')\n",
        "        activity = False\n",
        "        # The outputs condition on the winner of the race\n",
        "        # and perform their own race to provide a state.\n",
        "        outputw = self.wout(time, inputbest)\n",
        "        print(f'\\n\\n------\\n\\nDecoder.__call__ OUTPUT\\n\\n-----\\n\\n')\n",
        "        for outputid in self.sort(self.outputs, outputw):\n",
        "          output = self.outputs[outputid]\n",
        "          try:\n",
        "            # The output is applied to *all* of the sample values.\n",
        "            # It's important to mix states across the swarm to allow\n",
        "            # the analogy to continuity.\n",
        "            point    = output(sample)\n",
        "            activity = True\n",
        "            hidden.append(point)\n",
        "            print(f'Decoder.__call__ outputid={outputid} {point} Ok')\n",
        "            break\n",
        "          except ValueError:\n",
        "            print(f'Decoder.__call__ outputid={outputid} False')\n",
        "        if not activity:\n",
        "          print(f'Decoder.__call__ outputid={outputid} Err')\n",
        "          raise ValueError()\n",
        "      # The final states race with the initial states.\n",
        "      target = []\n",
        "      for i in range(self.purity):\n",
        "        if np.random.random() < residualw:\n",
        "          state = np.random.choice(hidden)\n",
        "          print(f'Decoder.__call__ residual hidden {state}')\n",
        "        else:\n",
        "          state = np.random.choice(swarm)\n",
        "          print(f'Decoder.__call__ residual initial {state}')\n",
        "        target.append(state)\n",
        "      swarm = target\n",
        "    return swarm"
      ],
      "metadata": {
        "id": "lX3hKo6RkB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Repository:\n",
        "  llm: Llama\n",
        "\n",
        "  def __init__(self, llm):\n",
        "    self.llm = llm\n",
        "\n",
        "  def input(self, input):\n",
        "    def map_state(x):\n",
        "      value = get_tag_body(x, 'value')\n",
        "      print(f'input/map_state: value={value}')\n",
        "      match value:\n",
        "        case 'True':\n",
        "          return True\n",
        "        case 'False':\n",
        "          return False\n",
        "        case _:\n",
        "          raise ValueError(f'Repository.input unknown value {value}')\n",
        "    def reduce_state(xs):\n",
        "      numbers = [1 if bool(x) else 0 for x in xs]\n",
        "      average = sum(numbers)/len(xs)\n",
        "      print(f'input/reduce_state: xs={xs} average={average}')\n",
        "      return average > 0.5\n",
        "    def body(state):\n",
        "      get_state = f'''\n",
        "Consider the following text-to-image prompt:\n",
        "\n",
        "```\n",
        "{state}\n",
        "```\n",
        "\n",
        "{input}\n",
        "\n",
        "Think about it carefully, then respond with either True or False\n",
        "in <value> tags, like this: <value>True</value> or <value>False</value>.\n",
        "'''.strip()\n",
        "      state = self.llm.reduce([get_state], map_state, reduce_state)\n",
        "      print(f'input/state={state}')\n",
        "      return state\n",
        "    return body\n",
        "\n",
        "  def output(self, output):\n",
        "    def map_output(x):\n",
        "      value = get_tag_body(x, 'value')\n",
        "      print(f'output/map_output: value={value}')\n",
        "      return value\n",
        "    def reduce_output(xs):\n",
        "      print(f'output/reduce_output: xs={xs}')\n",
        "      return xs[0]\n",
        "    def body(input, sample):\n",
        "      get_state = f'''\n",
        "Consider the following text-to-image prompts:\n",
        "\n",
        "```\n",
        "{sample}\n",
        "```\n",
        "\n",
        "These prompts have something in common: they all satisfy the\n",
        "following condition:\n",
        "\n",
        "```\n",
        "{input}\n",
        "```\n",
        "\n",
        "and they are going to be transformed according to the following\n",
        "operation:\n",
        "\n",
        "```\n",
        "{output}\n",
        "```\n",
        "\n",
        "Think of an interesting way to combine all of these prompts in\n",
        "to a single prompt based on this information. When you come up\n",
        "with a prompt, put it in <value></value> tags. Keep your prompt\n",
        "short and terse while including as much visual detail as\n",
        "possible.\n",
        "'''.strip()\n",
        "      def map_state(x):\n",
        "        value = get_tag_body(x, 'value')\n",
        "        print(f'output/map_state: x={x}')\n",
        "        return value\n",
        "      def reduce_state(xs):\n",
        "        print(f'output/map_state: xs={xs}')\n",
        "        return xs[0]\n",
        "      state = self.llm.reduce([get_state], map_state, reduce_state)\n",
        "      print(f'output/state = {state}')\n",
        "      return state\n",
        "    return body"
      ],
      "metadata": {
        "id": "ux4-dfgfgn3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = Repository(llm)\n",
        "\n",
        "inputs = [\n",
        "    # repo.input('Does this prompt mention men other than the artist?'),\n",
        "    # repo.input('Does this prompt mention women other than the artist?'),\n",
        "    repo.input('Does this prompt mention a famous artist?'),\n",
        "    repo.input('Does this prompt mention people other than the artist?'),\n",
        "    repo.input('Does this prompt not mention people other than the artist?'),\n",
        "    # repo.input('Is this a classical painting?'),\n",
        "    repo.input('Is this an anime illustration?'),\n",
        "    # repo.input('Does this artwork belong to the Renaissance period?'),\n",
        "    repo.input('Is this a modern abstract artwork?'),\n",
        "    repo.input('Is this piece in the style of Impressionism?'),\n",
        "    # repo.input('Does this resemble a Baroque painting?'),\n",
        "    # repo.input('Is this artwork in the style of Cubism?'),\n",
        "    # repo.input('Is the artist associated with the Surrealism movement?'),\n",
        "    repo.input('Does this image use techniques typical of watercolor painting?'),\n",
        "    repo.input('Is this artwork a digital creation?'),\n",
        "    repo.input('Does this prompt mention Pixiv?'),\n",
        "    repo.input('Does this prompt mention a man?'),\n",
        "    repo.input('Does this prompt mention a woman?'),\n",
        "    repo.input('Does this prompt mention \"illustration\"?'),\n",
        "    # repo.input('Does this represent a form of street art?'),\n",
        "    # repo.input('Is this a piece of Gothic art?'),\n",
        "    # repo.input('Is this image in the style of Art Nouveau?'),\n",
        "    # repo.input('Is this artwork part of the Pop Art movement?'),\n",
        "    repo.input('Does this belong to the Abstract Expressionism style?'),\n",
        "    # repo.input('Is this a Realism artwork?'),\n",
        "    # repo.input('Does this represent Minimalism?'),\n",
        "    # repo.input('Is this artwork done in the Art Deco style?'),\n",
        "    # repo.input('Does this piece use techniques of Neo-Impressionism?'),\n",
        "    # repo.input('Is this artwork influenced by Futurism?'),\n",
        "]\n",
        "outputs = [\n",
        "    repo.output('Make this an anime illustration.'),\n",
        "    repo.output('Make this a classical painting.'),\n",
        "    repo.output('Transform this image to reflect the Renaissance art style.'),\n",
        "    repo.output('Create this image in a modern abstract style.'),\n",
        "    repo.output('Convert this to an Impressionist style painting.'),\n",
        "    repo.output('Reimagine this as a Baroque period painting.'),\n",
        "    repo.output('Adapt this image to the Cubism art style.'),\n",
        "    repo.output('Render this image in a Surrealist style.'),\n",
        "    repo.output('Use watercolor techniques for this image.'),\n",
        "    repo.output('Create this artwork using digital media.'),\n",
        "    repo.output('Style this image as street art.'),\n",
        "    repo.output('Transform this into a Gothic art piece.'),\n",
        "    repo.output('Create this image in the style of Art Nouveau.'),\n",
        "    repo.output('Convert this to the Pop Art style.'),\n",
        "    repo.output('Adapt this image to Abstract Expressionism.'),\n",
        "    repo.output('Render this image as a Realism artwork.'),\n",
        "    repo.output('Style this artwork with Minimalist techniques.'),\n",
        "    repo.output('Create this in the Art Deco style.'),\n",
        "    repo.output('Use Neo-Impressionist techniques for this image.'),\n",
        "    repo.output('Reimagine this artwork in the style of Futurism.'),\n",
        "]"
      ],
      "metadata": {
        "id": "eCub1npZss8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_classical = inputs[0]\n",
        "fst = 'A digital art illustration by Ilya Kuvshinov.'\n",
        "snd = 'An oil painting by John Singer Sargent'\n",
        "print(f'{fst} = {is_classical(fst)}')\n",
        "print(f'{snd} = {is_classical(snd)}')\n",
        "\n",
        "make_anime = outputs[0]\n",
        "response = make_anime(\n",
        "  'Is this a classical painting?',\n",
        "  [\n",
        "    'An oil painting of a woman holding a parasol by John Singer Sargent',\n",
        "    'A still life of fruits on a table by Joaquin Sorolla',\n",
        "    'A scene from Greek mythology by Leonardo da Vinci',\n",
        "  ],\n",
        ")"
      ],
      "metadata": {
        "id": "u9vBKtmu3gdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}