{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "E6R7nSA6c8sf",
        "Ij79EHtaNDCt",
        "CUOAr6RddAdK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prelude\n",
        "\n"
      ],
      "metadata": {
        "id": "uwIzSYF_iLxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Resonators**](https://github.com/0xmaddie/0xmaddie/blob/main/resonators)\n",
        "is a Python library that uses data races and particle swarm dynamics\n",
        "to approximate functions. You can train a resonator like a transformer\n",
        "but it uses Python objects instead of vectors.\n",
        "\n",
        "## Particle swarms and oracle machines\n",
        "How does \"swarm intelligence\" work? A logical dependence on an\n",
        "implicit function representation observed by repeated measurement of\n",
        "collective behavior is a type of non-algorithmic computation because\n",
        "there's no effective procedure that would give you that information.\n",
        "\n",
        "You can use a particle swarm to train something called a component\n",
        "system â€” like a Turing machine or a bunch of Python or Lisp functions\n",
        "â€” in a manner similar to a neural net. The idea is to use the\n",
        "priorities of racing threads as an implicit representation of an\n",
        "energy function learned from a dataset.\n",
        "\n",
        "The important part is that each individual thread operation can only\n",
        "use data that is averaged across every thread. This provides an\n",
        "analogy to continuity and allows you to pass to the mean field limit,\n",
        "so you can optimize in a manner similar to a neural net.\n",
        "\n",
        "Imagine a class of programs written as lists of rules of the following\n",
        "form: If the state has a certain property, transform the state in a\n",
        "certain way. To execute these programs, evaluate the conditions in the\n",
        "order they are written until one is true, and then apply the\n",
        "corresponding transformation.\n",
        "\n",
        "We'd like to add weights to the space of all possible programs of this\n",
        "shape and tune them in alignment with a dataset. In other words, we'd\n",
        "like to create an oracle machine. The resonator is a machine of this\n",
        "type that uses an analogy to continuous functions through particle\n",
        "swarm dynamics to explore this space of programs.\n",
        "\n",
        "The resonator contains lists of every possible property and\n",
        "transformation, respectively called the \"inputs\" and the\n",
        "\"outputs\". When a layer is presented with a swarm of states, the\n",
        "inputs race according to their advice. The advice is provided in the\n",
        "form of the bias of a coin; on each step of the race the coins\n",
        "represent the probability that the respective input will be next in\n",
        "line until the inputs are sorted.\n",
        "\n",
        "Then, in the sorted order, the inputs attempt to provide a measurement\n",
        "of the swarm states that satisfy some property. If an input is unable\n",
        "to provide the minimum number of states required for a measurement,\n",
        "then the search proceeds with the next input in line. If no inputs are\n",
        "able to provide a measurement, the procedure raises an exception.\n",
        "\n",
        "If the inputs are able to provide a measurement, then the outputs\n",
        "condition on the winner of the input race and perform their own race\n",
        "in the same manner. The winner of the output race then combines the\n",
        "entire measurement of states into a single state in a manner similar\n",
        "to a crossover operation from genetic programming. It's important that\n",
        "the output's final state depends on many states sampled from the swarm\n",
        "at once in order to provide the analogy to continuity.\n",
        "\n",
        "This input-output process is repeated until a measurement of states\n",
        "has been provided by the outputs. Then, this measurement races with\n",
        "the initial states according to the advice as a type of residual\n",
        "connection. The idea is that the probabilities of all of these events\n",
        "are an implicit representation of a function learned from a\n",
        "dataset. In this sense, the coins are an oracle provided to a machine\n",
        "allowing it to self-organize.\n"
      ],
      "metadata": {
        "id": "XBeyrgZNNEMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction"
      ],
      "metadata": {
        "id": "7ry3CWWxMPCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "8OZwrT4Ij_9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Decoder:\n",
        "  def __init__(self, inputs, outputs, weights):\n",
        "    self.inputs  = inputs\n",
        "    self.outputs = outputs\n",
        "    self.weights = weights\n",
        "\n",
        "  @property\n",
        "  def weights_per_layer(self):\n",
        "    return len(self.inputs) + len(self.inputs) * len(self.outputs) + 1\n",
        "\n",
        "  def input_weights(self, layer):\n",
        "    start_index = layer * self.weights_per_layer()\n",
        "    return self.weights[start_index:start_index + len(self.inputs)]\n",
        "\n",
        "  def output_weights(self, layer, input_index):\n",
        "    start_index = layer * self.weights_per_layer()\n",
        "    output_start_index = start_index + len(self.inputs)\n",
        "    specific_input_output_start = output_start_index + input_index * len(self.outputs)\n",
        "    return self.weights[specific_input_output_start:specific_input_output_start + len(self.outputs)]\n",
        "\n",
        "  def residual_weights(self, layer):\n",
        "    start_index = layer * self.weights_per_layer()\n",
        "    residual_start_index = start_index + len(self.inputs) + len(self.inputs) * len(self.outputs)\n",
        "    specific_residual_index = residual_start_index + input_index * len(self.outputs) + output_index\n",
        "    return self\n",
        "\n",
        "  def sort(self, components, weights):\n",
        "    # Each weight is the probability that the corresponding\n",
        "    # component will be next in line.\n",
        "    indices = np.random.choice(\n",
        "      len(inputs),\n",
        "      size=len(inputs),\n",
        "      replace=False,\n",
        "      p=weights,\n",
        "    )\n",
        "    return indices\n",
        "\n",
        "  def __call__(self, swarm):\n",
        "    for time in range(self.layers):\n",
        "      inputw    = self.input_weights(time)\n",
        "      residualw = self.residual_weights(time)\n",
        "      hidden    = []\n",
        "      for i in range(self.purity):\n",
        "        inputbest = None\n",
        "        for inputid in self.sort(self.inputs, inputw):\n",
        "          input  = self.inputs[inputid]\n",
        "          sample = []\n",
        "          for state in swarm:\n",
        "            if input(state):\n",
        "              sample.append(state)\n",
        "            if len(sample) >= threshold:\n",
        "              inputbest = inputid\n",
        "              break\n",
        "        if len(sample) < threshold:\n",
        "          raise ValueError()\n",
        "        activity = False\n",
        "        outputw  = self.output_weights(time, inputbest)\n",
        "        for outputid in self.sort(self.outputs, outputw):\n",
        "          output = self.outputs[outputid]\n",
        "          try:\n",
        "            point    = output(sample)\n",
        "            activity = True\n",
        "            hidden.append(point)\n",
        "            break\n",
        "          except OutputError:\n",
        "            pass\n",
        "        if not activity:\n",
        "          raise ValueError()\n",
        "      target = []\n",
        "      for i in range(self.purity):\n",
        "        if self.coin() < residualw:\n",
        "          state = np.random.choice(hidden)\n",
        "        else:\n",
        "          state = np.random.choice(swarm)\n",
        "        target.append(state)\n",
        "      swarm = target\n",
        "    return swarm"
      ],
      "metadata": {
        "id": "lX3hKo6RkB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modifiers = [\n",
        "    'oil painting',\n",
        "    'watercolor',\n",
        "    'digital art',\n",
        "    'sketch',\n",
        "    'charcoal drawing',\n",
        "    'acrylic on canvas',\n",
        "    'surrealism',\n",
        "    'impressionism',\n",
        "    'realism',\n",
        "    'abstract',\n",
        "    'cubism',\n",
        "    'art nouveau',\n",
        "    'art deco',\n",
        "    'renaissance',\n",
        "    'baroque',\n",
        "    'neoclassicism',\n",
        "    'modernism',\n",
        "    'expressionism',\n",
        "    'anime style',\n",
        "    'manga style',\n",
        "    'comic book style',\n",
        "    'black and white',\n",
        "    'monochrome',\n",
        "    'pastel colors',\n",
        "    'vibrant colors',\n",
        "    'noir',\n",
        "    'sepia tone',\n",
        "    'minimalist',\n",
        "    'detailed',\n",
        "    'fantasy',\n",
        "    'sci-fi',\n",
        "    'post-apocalyptic',\n",
        "    'steampunk',\n",
        "    'cyberpunk',\n",
        "    'historical',\n",
        "    'medieval',\n",
        "    'futuristic',\n",
        "    'ethereal',\n",
        "    'gloomy',\n",
        "    'mystical',\n",
        "    'peaceful',\n",
        "    'chaotic',\n",
        "    'dreamlike',\n",
        "    'night scene',\n",
        "    'sunset',\n",
        "    'dawn',\n",
        "    'portrait',\n",
        "    'landscape',\n",
        "    'cityscape',\n",
        "    'seascape',\n",
        "    'still life',\n",
        "    'action scene',\n",
        "    'close-up',\n",
        "    'wide angle',\n",
        "    'from above',\n",
        "    'from below',\n",
        "    'side view',\n",
        "    'backlit',\n",
        "    'silhouetted',\n",
        "    'high contrast',\n",
        "    'soft lighting',\n",
        "    'harsh lighting',\n",
        "    'textured',\n",
        "    'smooth',\n",
        "    'brush strokes visible',\n",
        "    'blurred',\n",
        "    'sharp focus',\n",
        "    'panoramic view',\n",
        "    'macro',\n",
        "    'micro',\n",
        "    'pop art',\n",
        "    'street art',\n",
        "    'mural',\n",
        "    'graffiti',\n",
        "    'papercut',\n",
        "    'collage',\n",
        "    'mosaic',\n",
        "    'embroidery',\n",
        "    'tapestry',\n",
        "    'glass art',\n",
        "    'metal art',\n",
        "    'wood carving',\n",
        "    'ceramic',\n",
        "    'sculpture',\n",
        "    'installation art',\n",
        "    'performance art',\n",
        "    'video art',\n",
        "    'interactive art',\n",
        "    'AI-generated',\n",
        "    'handmade',\n",
        "    'recycled materials',\n",
        "    'ecofriendly materials',\n",
        "    'using natural light',\n",
        "    'indoor scene',\n",
        "    'outdoor scene',\n",
        "    'underwater scene',\n",
        "    'in the clouds',\n",
        "    'in space',\n",
        "    'celestial',\n",
        "    'mythological',\n",
        "    'biblical',\n",
        "    'historical figure',\n",
        "    'famous person',\n",
        "    'fictional character',\n",
        "    'animal',\n",
        "    'plant',\n",
        "    'abstract form',\n",
        "    'geometric pattern',\n",
        "    'floral pattern',\n",
        "    'paisley pattern',\n",
        "    'stripes',\n",
        "    'polka dots',\n",
        "    'checkerboard',\n",
        "    'spirals',\n",
        "    'wavy',\n",
        "    'zigzag',\n",
        "    'stippling',\n",
        "    'crosshatching',\n",
        "    'half-tone',\n",
        "    'glitch art',\n",
        "    'low poly',\n",
        "    'high resolution',\n",
        "    'low resolution',\n",
        "    'pixel art',\n",
        "    '3D model',\n",
        "    '2D illustration',\n",
        "    'VR environment',\n",
        "    'AR effects',\n",
        "    'motion blur',\n",
        "    'time-lapse',\n",
        "    'stop-motion',\n",
        "    'cinemagraph',\n",
        "    'long exposure',\n",
        "    'multiple exposures',\n",
        "    'HDR',\n",
        "    'panorama'\n",
        "]\n",
        "\n",
        "inputs  = []\n",
        "outputs = []\n",
        "\n",
        "# Populating the lists using the helper functions\n",
        "for modifier in modifiers:\n",
        "  # Add both presence and absence checks for each keyword\n",
        "  inputs.append(make_input(modifier, presence=True))\n",
        "  inputs.append(make_input(modifier, presence=False))\n",
        "\n",
        "  # Add both adding and removing functionality for each keyword\n",
        "  outputs.append(make_output(modifier, adding=True))\n",
        "  outputs.append(make_output(modifier, adding=False))"
      ],
      "metadata": {
        "id": "94e8XmihvlVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_weights = len(inputs)+len(inputs)*len(outputs)+1\n",
        "weights = # a random numpy array that's num_weights long\n",
        "decoder = Decoder(\n",
        "  inputs=inputs,\n",
        "  outputs=outputs,\n",
        "  weights=weights,\n",
        ")\n",
        "initial = \"oil painting\"\n",
        "final   = decoder(initial)\n",
        "print(final)"
      ],
      "metadata": {
        "id": "VrTXkFINx4yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning"
      ],
      "metadata": {
        "id": "CUOAr6RddAdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass(frozen=True)\n",
        "class Optimizer:\n",
        "  facc: float\n",
        "  fres: float\n",
        "  rate: float\n",
        "  decay: float\n",
        "\n",
        "  def __call__(self, pos, acc, grad):\n",
        "    hacc  = self.interp(grad, acc, self.facc)\n",
        "    res   = self.interp(grad, acc, self.fres)\n",
        "    mix   = pos*self.decay+sign(res)\n",
        "    delta = mix*self.rate\n",
        "    return delta, hacc\n",
        "\n",
        "class Tuner:\n",
        "  quota: int\n",
        "  purity: int\n",
        "  density: int\n",
        "  update: callable\n",
        "\n",
        "  def measure(self, machine, data):\n",
        "    energy = 0\n",
        "    for i in range(self.purity):\n",
        "      (init, eval)  = data()\n",
        "      energy       += eval(machine(init))\n",
        "    return energy/self.purity\n",
        "\n",
        "  def __call__(self, init, cons, data):\n",
        "    pos  = []\n",
        "    acc  = []\n",
        "    loss = []\n",
        "    for _ in range(self.quota):\n",
        "      for i in range(self.density):\n",
        "        machine = cons(pos[i])\n",
        "        loss[i] = self.measure(machine, data)\n",
        "      center  = self.average(pos, loss)\n",
        "      teacher = cons(center)\n",
        "      cutoff  = self.measure(teacher, data)\n",
        "      for i in range(self.density):\n",
        "        if loss[i] <= cutoff:\n",
        "          continue\n",
        "        compass  = pos[i]-center\n",
        "        sort     = compass*self.coherence\n",
        "        search   = (compass@compass)*self.noise()\n",
        "        gradient = sort+search\n",
        "        vel, acc = self.update(pos[i], acc[i], gradient)\n",
        "        pos[i]  += vel\n",
        "        acc[i]   = acc\n",
        "    return self.average(pos, loss)"
      ],
      "metadata": {
        "id": "BOHgnO8ib_3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}