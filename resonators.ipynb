{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "E6R7nSA6c8sf",
        "Ij79EHtaNDCt",
        "CUOAr6RddAdK"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prelude\n",
        "\n"
      ],
      "metadata": {
        "id": "uwIzSYF_iLxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Resonators**](https://github.com/0xmaddie/0xmaddie/blob/main/resonators)\n",
        "is a Python library that uses data races and particle swarm dynamics\n",
        "to approximate functions. You can train a resonator like a transformer\n",
        "but it uses Python objects instead of vectors.\n",
        "\n",
        "## Particle swarms and oracle machines\n",
        "How does \"swarm intelligence\" work? A logical dependence on an\n",
        "implicit function representation observed by repeated measurement of\n",
        "collective behavior is a type of non-algorithmic computation because\n",
        "there's no effective procedure that would give you that information.\n",
        "\n",
        "You can use a particle swarm to train something called a component\n",
        "system — like a Turing machine or a bunch of Python or Lisp functions\n",
        "— in a manner similar to a neural net. The idea is to use the\n",
        "priorities of racing threads as an implicit representation of an\n",
        "energy function learned from a dataset.\n",
        "\n",
        "The important part is that each individual thread operation can only\n",
        "use data that is averaged across every thread. This provides an\n",
        "analogy to continuity and allows you to pass to the mean field limit,\n",
        "so you can optimize in a manner similar to a neural net.\n",
        "\n",
        "Imagine a class of programs written as lists of rules of the following\n",
        "form: If the state has a certain property, transform the state in a\n",
        "certain way. To execute these programs, evaluate the conditions in the\n",
        "order they are written until one is true, and then apply the\n",
        "corresponding transformation.\n",
        "\n",
        "We'd like to add weights to the space of all possible programs of this\n",
        "shape and tune them in alignment with a dataset. In other words, we'd\n",
        "like to create an oracle machine. The resonator is a machine of this\n",
        "type that uses an analogy to continuous functions through particle\n",
        "swarm dynamics to explore this space of programs.\n",
        "\n",
        "The resonator contains lists of every possible property and\n",
        "transformation, respectively called the \"inputs\" and the\n",
        "\"outputs\". When a layer is presented with a swarm of states, the\n",
        "inputs race according to their advice. The advice is provided in the\n",
        "form of the bias of a coin; on each step of the race the coins\n",
        "represent the probability that the respective input will be next in\n",
        "line until the inputs are sorted.\n",
        "\n",
        "Then, in the sorted order, the inputs attempt to provide a measurement\n",
        "of the swarm states that satisfy some property. If an input is unable\n",
        "to provide the minimum number of states required for a measurement,\n",
        "then the search proceeds with the next input in line. If no inputs are\n",
        "able to provide a measurement, the procedure raises an exception.\n",
        "\n",
        "If the inputs are able to provide a measurement, then the outputs\n",
        "condition on the winner of the input race and perform their own race\n",
        "in the same manner. The winner of the output race then combines the\n",
        "entire measurement of states into a single state in a manner similar\n",
        "to a crossover operation from genetic programming. It's important that\n",
        "the output's final state depends on many states sampled from the swarm\n",
        "at once in order to provide the analogy to continuity.\n",
        "\n",
        "This input-output process is repeated until a measurement of states\n",
        "has been provided by the outputs. Then, this measurement races with\n",
        "the initial states according to the advice as a type of residual\n",
        "connection. The idea is that the probabilities of all of these events\n",
        "are an implicit representation of a function learned from a\n",
        "dataset. In this sense, the coins are an oracle provided to a machine\n",
        "allowing it to self-organize.\n"
      ],
      "metadata": {
        "id": "XBeyrgZNNEMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google\n",
        "google.colab.drive.mount('/content/drive')\n",
        "!cp /content/drive/MyDrive/secret.py .\n",
        "import secret"
      ],
      "metadata": {
        "id": "q-aQyEETzQUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "SjxzCm_80O4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login()"
      ],
      "metadata": {
        "id": "LOw4lMy6552G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construction"
      ],
      "metadata": {
        "id": "7ry3CWWxMPCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder"
      ],
      "metadata": {
        "id": "8OZwrT4Ij_9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "class Decoder:\n",
        "  def __init__(self, inputs, outputs, weights, purity=100, width=12, threshold=4):\n",
        "    self.inputs    = inputs\n",
        "    self.outputs   = outputs\n",
        "    self.weights   = weights\n",
        "    self.purity    = purity\n",
        "    self.width     = width\n",
        "    self.threshold = threshold\n",
        "\n",
        "  @property\n",
        "  def density(self):\n",
        "    return len(self.inputs)*len(self.outputs)\n",
        "\n",
        "  # The number of weights per layer.\n",
        "  @property\n",
        "  def layer_capacity(self):\n",
        "    return len(self.inputs) + len(self.inputs) * len(self.outputs) + 1\n",
        "\n",
        "  @property\n",
        "  def layers(self):\n",
        "    return len(self.weights)//self.layer_capacity\n",
        "\n",
        "  @property\n",
        "  def capacity(self):\n",
        "    return len(self.weights)\n",
        "\n",
        "  # The weights associated with the inputs for a certain layer.\n",
        "  def win(self, layer):\n",
        "    lhs = layer * self.capacity\n",
        "    return self.weights[lhs:lhs+len(self.inputs)]\n",
        "\n",
        "  # The weights associated with the outputs for a certain layer.\n",
        "  def wout(self, layer, input_index):\n",
        "    input_lhs  = layer * self.capacity\n",
        "    output_lhs = input_lhs + len(self.inputs)\n",
        "    target_lhs = output_lhs + input_index * len(self.outputs)\n",
        "    return self.weights[target_lhs:target_lhs+len(self.outputs)]\n",
        "\n",
        "  # The weights associated with the residual for a certain layer.\n",
        "  def wres(self, layer):\n",
        "    input_lhs    = layer * self.capacity\n",
        "    residual_idx = input_lhs + len(self.inputs) + len(self.inputs) * len(self.outputs)\n",
        "    return self.weights[residual_idx]\n",
        "\n",
        "  def sort(self, components, weights):\n",
        "    # Each weight is the probability that the corresponding\n",
        "    # component will be next in line.\n",
        "    indices = np.random.choice(\n",
        "      len(self.inputs),\n",
        "      size=len(self.inputs),\n",
        "      replace=False,\n",
        "      p=scipy.special.softmax(weights),\n",
        "    )\n",
        "    return indices\n",
        "\n",
        "  def __call__(self, swarm):\n",
        "    for time in range(self.layers):\n",
        "      inputw    = self.win(time)\n",
        "      residualw = self.wres(time)\n",
        "      hidden    = []\n",
        "      for i in range(self.purity):\n",
        "        print(f'Decoder.__call__ iteration # {i}')\n",
        "        # The inputs race to provide a measurement.\n",
        "        sample = []\n",
        "        inputbest = None\n",
        "        inputlist = self.sort(self.inputs, inputw)\n",
        "        inputlist = list(reversed(inputlist))\n",
        "        while inputbest is None and len(inputlist) > 0:\n",
        "          inputid = inputlist.pop()\n",
        "          input = self.inputs[inputid]\n",
        "          sample.clear()\n",
        "          for state in swarm:\n",
        "            if input(state):\n",
        "              print(f'Decoder.__call__ inputid={inputid} {state} True')\n",
        "              sample.append(state)\n",
        "            else:\n",
        "              print(f'Decoder.__call__ inputid={inputid} {state} False')\n",
        "            if len(sample) >= self.threshold:\n",
        "              inputbest = inputid\n",
        "              break\n",
        "        # If no inputs were able to provide a large enough measurement\n",
        "        # then an exception is raised.\n",
        "        if inputbest is None:\n",
        "          print(f'Decoder.__call__ inputid={inputid} Err')\n",
        "          raise ValueError()\n",
        "        assert len(sample) == self.threshold\n",
        "        print(f'Decoder.__call__ inputbest={inputbest} Ok')\n",
        "        activity = False\n",
        "        # The outputs condition on the winner of the race\n",
        "        # and perform their own race to provide a state.\n",
        "        outputw = self.wout(time, inputbest)\n",
        "        print(f'\\n\\n------\\n\\nDecoder.__call__ OUTPUT\\n\\n-----\\n\\n')\n",
        "        for outputid in self.sort(self.outputs, outputw):\n",
        "          output = self.outputs[outputid]\n",
        "          try:\n",
        "            # The output is applied to *all* of the sample values.\n",
        "            # It's important to mix states across the swarm to allow\n",
        "            # the analogy to continuity.\n",
        "            point    = output(sample)\n",
        "            activity = True\n",
        "            hidden.append(point)\n",
        "            print(f'Decoder.__call__ outputid={outputid} {point} Ok')\n",
        "            break\n",
        "          except ValueError:\n",
        "            print(f'Decoder.__call__ outputid={outputid} False')\n",
        "        if not activity:\n",
        "          print(f'Decoder.__call__ outputid={outputid} Err')\n",
        "          raise ValueError()\n",
        "      # The final states race with the initial states.\n",
        "      target = []\n",
        "      for i in range(self.purity):\n",
        "        if np.random.random() < residualw:\n",
        "          state = np.random.choice(hidden)\n",
        "          print(f'Decoder.__call__ residual hidden {state}')\n",
        "        else:\n",
        "          state = np.random.choice(swarm)\n",
        "          print(f'Decoder.__call__ residual initial {state}')\n",
        "        target.append(state)\n",
        "      swarm = target\n",
        "    return swarm"
      ],
      "metadata": {
        "id": "lX3hKo6RkB7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "class Llama:\n",
        "  tokenizer: transformers.AutoTokenizer\n",
        "  model: transformers.AutoModelForCausalLM\n",
        "  system_prompt: str\n",
        "  temperature: float\n",
        "  max_new_tokens: int\n",
        "  terminators: list\n",
        "  purity: int\n",
        "  quota: int\n",
        "\n",
        "  def __init__(\n",
        "    self,\n",
        "    system_prompt: str = 'You are a helpful assistant.',\n",
        "    temperature: float = 0.7,\n",
        "    max_new_tokens: int = 4096,\n",
        "    purity: int = 100,\n",
        "    quota: int = 1000,\n",
        "    tokenizer = None,\n",
        "    model = None,\n",
        "  ):\n",
        "    model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "    self.tokenizer = tokenizer or transformers.AutoTokenizer.from_pretrained(\n",
        "      model_name,\n",
        "      #cache_dir=secret.home,\n",
        "      #local_files_only=True,\n",
        "    )\n",
        "    self.model = model or transformers.AutoModelForCausalLM.from_pretrained(\n",
        "      model_name,\n",
        "      device_map=\"auto\",\n",
        "      load_in_8bit=True,\n",
        "      #cache_dir=secret.home,\n",
        "      #local_files_only=True,\n",
        "    )\n",
        "    self.terminators = [\n",
        "      self.tokenizer.eos_token_id,\n",
        "      self.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "    self.system_prompt  = system_prompt\n",
        "    self.temperature    = temperature\n",
        "    self.max_new_tokens = max_new_tokens\n",
        "    self.purity         = purity\n",
        "    self.quota          = quota\n",
        "\n",
        "  def __apply_chat_template(self, state):\n",
        "    prompt = [{ 'role': 'system', 'content': self.system_prompt }]\n",
        "    for index, content in enumerate(state):\n",
        "      if index%2 == 0:\n",
        "        role = 'user'\n",
        "      else:\n",
        "        role = 'assistant'\n",
        "      prompt.append({ 'role': role, 'content': content })\n",
        "    print(f'<prompt>{prompt}</prompt>')\n",
        "    input_ids = self.tokenizer.apply_chat_template(\n",
        "      prompt,\n",
        "      #tokenize=True,\n",
        "      add_generation_prompt=True,\n",
        "      return_tensors='pt',\n",
        "    ).to(self.model.device)\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "  def get(self, state):\n",
        "    source_ids = self.__apply_chat_template(state)\n",
        "    targets    = self.model.generate(\n",
        "      source_ids,\n",
        "      max_new_tokens=self.max_new_tokens,\n",
        "      do_sample=True,\n",
        "      temperature=self.temperature,\n",
        "      eos_token_id=self.terminators,\n",
        "    )\n",
        "    target_ids = targets[0][source_ids.shape[-1]:]\n",
        "    target     = self.tokenizer.decode(target_ids, skip_special_tokens=True)\n",
        "    print(f'Llama.get got string: {target}')\n",
        "    return target\n",
        "\n",
        "  def reduce(self, input, map, reduce):\n",
        "    quota   = self.quota\n",
        "    samples = []\n",
        "    while quota > 0 and len(samples) < self.purity:\n",
        "      quota -= 1\n",
        "      samples.clear()\n",
        "      try:\n",
        "        object = map(self.get(input))\n",
        "        print(f'Llama.reduce got object: {object}')\n",
        "        samples.append(object)\n",
        "      except ValueError:\n",
        "        pass\n",
        "    if len(samples) < self.purity and quota == 0:\n",
        "      raise ValueError(f'quota consumed')\n",
        "    output = reduce(samples)\n",
        "    return output"
      ],
      "metadata": {
        "id": "94e8XmihvlVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model = llm.model\n",
        "_tokenizer = llm.tokenizer"
      ],
      "metadata": {
        "id": "U-kW8DGdAZJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Llama(\n",
        "  system_prompt=f'''\n",
        "You are a helpful assistant.\n",
        "'''.strip(),\n",
        "  temperature=0.7,\n",
        "  max_new_tokens=1024,\n",
        "  purity=1,\n",
        "  quota=3,\n",
        "  #model=_model,\n",
        "  #tokenizer=_tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "8gcxnxAolx6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_tag_body(document, tag_name):\n",
        "  # Perform string replacement to transform <value> tags into <div class=\"value\">\n",
        "  document = document.replace(f\"<{tag_name}>\", f'<div class=\"{tag_name}\">').replace(f\"</{tag_name}>\", \"</div>\")\n",
        "  # Parse the modified HTML document with BeautifulSoup\n",
        "  soup = BeautifulSoup(document, 'html.parser')\n",
        "  # Find all divs with the class \"value\"\n",
        "  value_divs = soup.find_all('div', class_=tag_name)\n",
        "  # Ensure there is exactly one div with class \"value\"\n",
        "  if len(value_divs) != 1:\n",
        "    raise ValueError(f\"Expected exactly one <div class='{tag_name}'> tag, but found {len(value_divs)}.\")\n",
        "  # Return the text content of the <div class=\"value\">\n",
        "  return value_divs[0].get_text()\n",
        "\n",
        "class Repository:\n",
        "  llm: Llama\n",
        "\n",
        "  def __init__(self, llm):\n",
        "    self.llm = llm\n",
        "\n",
        "  def input(self, input):\n",
        "    def map_state(x):\n",
        "      value = get_tag_body(x, 'value')\n",
        "      print(f'input/map_state: value={value}')\n",
        "      match value:\n",
        "        case 'True':\n",
        "          return True\n",
        "        case 'False':\n",
        "          return False\n",
        "        case _:\n",
        "          raise ValueError(f'Repository.input unknown value {value}')\n",
        "    def reduce_state(xs):\n",
        "      numbers = [1 if bool(x) else 0 for x in xs]\n",
        "      average = sum(numbers)/len(xs)\n",
        "      print(f'input/reduce_state: xs={xs} average={average}')\n",
        "      return average > 0.5\n",
        "    def body(state):\n",
        "      get_state = f'''\n",
        "Consider the following text-to-image prompt:\n",
        "\n",
        "```\n",
        "{state}\n",
        "```\n",
        "\n",
        "{input}\n",
        "\n",
        "Think about it carefully, then respond with either True or False\n",
        "in <value> tags, like this: <value>True</value> or <value>False</value>.\n",
        "'''.strip()\n",
        "      state = self.llm.reduce([get_state], map_state, reduce_state)\n",
        "      print(f'input/state={state}')\n",
        "      return state\n",
        "    return body\n",
        "\n",
        "  def output(self, output):\n",
        "    def map_output(x):\n",
        "      value = get_tag_body(x, 'value')\n",
        "      print(f'output/map_output: value={value}')\n",
        "      return value\n",
        "    def reduce_output(xs):\n",
        "      print(f'output/reduce_output: xs={xs}')\n",
        "      return xs[0]\n",
        "    def body(input, sample):\n",
        "      get_state = f'''\n",
        "Consider the following text-to-image prompts:\n",
        "\n",
        "```\n",
        "{sample}\n",
        "```\n",
        "\n",
        "These prompts have something in common: they all satisfy the\n",
        "following condition:\n",
        "\n",
        "```\n",
        "{input}\n",
        "```\n",
        "\n",
        "and they are going to be transformed according to the following\n",
        "operation:\n",
        "\n",
        "```\n",
        "{output}\n",
        "```\n",
        "\n",
        "Think of an interesting way to combine all of these prompts in\n",
        "to a single prompt based on this information. When you come up\n",
        "with a prompt, put it in <value></value> tags. Keep your prompt\n",
        "short and terse while including as much visual detail as\n",
        "possible.\n",
        "'''.strip()\n",
        "      def map_state(x):\n",
        "        value = get_tag_body(x, 'value')\n",
        "        print(f'output/map_state: x={x}')\n",
        "        return value\n",
        "      def reduce_state(xs):\n",
        "        print(f'output/map_state: xs={xs}')\n",
        "        return xs[0]\n",
        "      state = self.llm.reduce([get_state], map_state, reduce_state)\n",
        "      print(f'output/state = {state}')\n",
        "      return state\n",
        "    return body"
      ],
      "metadata": {
        "id": "BH-kHssBly7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo = Repository(llm)\n",
        "\n",
        "inputs = [\n",
        "    # repo.input('Does this prompt mention men other than the artist?'),\n",
        "    # repo.input('Does this prompt mention women other than the artist?'),\n",
        "    repo.input('Does this prompt mention a famous artist?'),\n",
        "    repo.input('Does this prompt mention people other than the artist?'),\n",
        "    repo.input('Does this prompt not mention people other than the artist?'),\n",
        "    # repo.input('Is this a classical painting?'),\n",
        "    repo.input('Is this an anime illustration?'),\n",
        "    # repo.input('Does this artwork belong to the Renaissance period?'),\n",
        "    repo.input('Is this a modern abstract artwork?'),\n",
        "    repo.input('Is this piece in the style of Impressionism?'),\n",
        "    # repo.input('Does this resemble a Baroque painting?'),\n",
        "    # repo.input('Is this artwork in the style of Cubism?'),\n",
        "    # repo.input('Is the artist associated with the Surrealism movement?'),\n",
        "    repo.input('Does this image use techniques typical of watercolor painting?'),\n",
        "    repo.input('Is this artwork a digital creation?'),\n",
        "    repo.input('Does this prompt mention Pixiv?'),\n",
        "    repo.input('Does this prompt mention a man?'),\n",
        "    repo.input('Does this prompt mention a woman?'),\n",
        "    repo.input('Does this prompt mention \"illustration\"?'),\n",
        "    # repo.input('Does this represent a form of street art?'),\n",
        "    # repo.input('Is this a piece of Gothic art?'),\n",
        "    # repo.input('Is this image in the style of Art Nouveau?'),\n",
        "    # repo.input('Is this artwork part of the Pop Art movement?'),\n",
        "    repo.input('Does this belong to the Abstract Expressionism style?'),\n",
        "    # repo.input('Is this a Realism artwork?'),\n",
        "    # repo.input('Does this represent Minimalism?'),\n",
        "    # repo.input('Is this artwork done in the Art Deco style?'),\n",
        "    # repo.input('Does this piece use techniques of Neo-Impressionism?'),\n",
        "    # repo.input('Is this artwork influenced by Futurism?'),\n",
        "]\n",
        "outputs = [\n",
        "    repo.output('Make this an anime illustration.'),\n",
        "    repo.output('Make this a classical painting.'),\n",
        "    repo.output('Transform this image to reflect the Renaissance art style.'),\n",
        "    repo.output('Create this image in a modern abstract style.'),\n",
        "    repo.output('Convert this to an Impressionist style painting.'),\n",
        "    repo.output('Reimagine this as a Baroque period painting.'),\n",
        "    repo.output('Adapt this image to the Cubism art style.'),\n",
        "    repo.output('Render this image in a Surrealist style.'),\n",
        "    repo.output('Use watercolor techniques for this image.'),\n",
        "    repo.output('Create this artwork using digital media.'),\n",
        "    repo.output('Style this image as street art.'),\n",
        "    repo.output('Transform this into a Gothic art piece.'),\n",
        "    repo.output('Create this image in the style of Art Nouveau.'),\n",
        "    repo.output('Convert this to the Pop Art style.'),\n",
        "    repo.output('Adapt this image to Abstract Expressionism.'),\n",
        "    repo.output('Render this image as a Realism artwork.'),\n",
        "    repo.output('Style this artwork with Minimalist techniques.'),\n",
        "    repo.output('Create this in the Art Deco style.'),\n",
        "    repo.output('Use Neo-Impressionist techniques for this image.'),\n",
        "    repo.output('Reimagine this artwork in the style of Futurism.'),\n",
        "]"
      ],
      "metadata": {
        "id": "eCub1npZss8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_classical = inputs[0]\n",
        "fst = 'A digital art illustration by Ilya Kuvshinov.'\n",
        "snd = 'An oil painting by John Singer Sargent'\n",
        "print(f'{fst} = {is_classical(fst)}')\n",
        "print(f'{snd} = {is_classical(snd)}')"
      ],
      "metadata": {
        "id": "u9vBKtmu3gdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_anime = outputs[0]\n",
        "response = make_anime(\n",
        "  'Is this a classical painting?',\n",
        "  [\n",
        "    'An oil painting of a woman holding a parasol by John Singer Sargent',\n",
        "    'A still life of fruits on a table by Joaquin Sorolla',\n",
        "    'A scene from Greek mythology by Leonardo da Vinci',\n",
        "  ],\n",
        ")"
      ],
      "metadata": {
        "id": "SGrthOvjEWad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "DMgqpFjtFgsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_weights = len(inputs)+len(inputs)*len(outputs)+1\n",
        "\n",
        "initial_state = [\n",
        "  \"A peaceful autumn landscape in the style of Claude Monet.\",\n",
        "  \"A vibrant street scene inspired by Edward Hopper's urban solitude.\",\n",
        "  \"A serene beach at sunset, reminiscent of Joaquin Sorolla's light-filled paintings.\",\n",
        "  \"A quiet forest path in the style of Gustav Klimt, using bold patterns and gold leaf.\",\n",
        "  \"A bustling café scene, capturing the energy of Vincent van Gogh's post-impressionistic style.\",\n",
        "  \"A calm lake with swans, painted in the impressionistic style of Berthe Morisot.\",\n",
        "  \"A simple still life of apples and oranges in the cubist style of Pablo Picasso.\",\n",
        "  \"A tranquil winter morning scene, inspired by Caspar David Friedrich's romantic landscapes.\",\n",
        "  \"A minimalist composition featuring a lone tree, in the style of Georgia O’Keeffe.\",\n",
        "  \"A playful abstract composition in the vibrant colors of Wassily Kandinsky.\",\n",
        "  \"A pastoral countryside in spring, evoking the peaceful scenes of John Constable.\",\n",
        "  \"A serene pond with lilies, influenced by Claude Monet’s impressionistic water lilies.\",\n",
        "  \"A bustling market square, inspired by Pieter Bruegel the Elder's detailed folk scenes.\",\n",
        "  \"A modern urban skyline at dusk, reflecting the futuristic themes of László Moholy-Nagy.\",\n",
        "  \"A gentle snowfall over a small village, reminiscent of Pieter Brueghel the Younger’s winter landscapes.\",\n",
        "  \"A futuristic cityscape with neon lights, styled like a top ArtStation digital artist.\",\n",
        "  \"A magical forest with bioluminescent plants, akin to works by a Pixiv fantasy artist.\",\n",
        "  \"A mech battle scene, in the style of a mechanical design specialist from ArtStation.\",\n",
        "  \"An ethereal underwater world, inspired by a Pixiv artist known for surreal themes.\",\n",
        "  \"Floating islands and whimsical structures, in a digital artist's visionary style from ArtStation.\",\n",
        "  \"Ancient ruins overtaken by nature, from a Pixiv environment artist.\",\n",
        "  \"A night market illuminated by lanterns, by an urban scene artist from ArtStation.\",\n",
        "  \"High fantasy city on a mountain, in the style of a fantasy artist from Pixiv.\",\n",
        "  \"A space station with advanced technology, designed by a sci-fi artist from ArtStation.\",\n",
        "  \"A snowy village with cozy, glowing windows, inspired by a winter scene artist from Pixiv.\",\n",
        "]\n",
        "initial_state = np.random.permutation(initial_state)\n",
        "decoder = Decoder(\n",
        "  inputs=inputs,\n",
        "  outputs=outputs,\n",
        "  weights=np.random.rand(num_weights),\n",
        "  purity=len(initial_state),\n",
        "  width=10,\n",
        "  threshold=2,\n",
        ")\n",
        "final_states = decoder(initial_state)\n",
        "print(final_states)"
      ],
      "metadata": {
        "id": "VrTXkFINx4yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning"
      ],
      "metadata": {
        "id": "CUOAr6RddAdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclasses.dataclass(frozen=True)\n",
        "class Optimizer:\n",
        "  facc: float\n",
        "  fres: float\n",
        "  rate: float\n",
        "  decay: float\n",
        "\n",
        "  def __call__(self, pos, acc, grad):\n",
        "    hacc  = self.interp(grad, acc, self.facc)\n",
        "    res   = self.interp(grad, acc, self.fres)\n",
        "    mix   = pos*self.decay+sign(res)\n",
        "    delta = mix*self.rate\n",
        "    return delta, hacc\n",
        "\n",
        "class Tuner:\n",
        "  quota: int\n",
        "  purity: int\n",
        "  density: int\n",
        "  update: callable\n",
        "\n",
        "  def measure(self, machine, data):\n",
        "    energy = 0\n",
        "    for i in range(self.purity):\n",
        "      (init, eval)  = data()\n",
        "      energy       += eval(machine(init))\n",
        "    return energy/self.purity\n",
        "\n",
        "  def __call__(self, init, cons, data):\n",
        "    pos  = []\n",
        "    acc  = []\n",
        "    loss = []\n",
        "    for _ in range(self.quota):\n",
        "      for i in range(self.density):\n",
        "        machine = cons(pos[i])\n",
        "        loss[i] = self.measure(machine, data)\n",
        "      center  = self.average(pos, loss)\n",
        "      teacher = cons(center)\n",
        "      cutoff  = self.measure(teacher, data)\n",
        "      for i in range(self.density):\n",
        "        if loss[i] <= cutoff:\n",
        "          continue\n",
        "        compass  = pos[i]-center\n",
        "        sort     = compass*self.coherence\n",
        "        search   = (compass@compass)*self.noise()\n",
        "        gradient = sort+search\n",
        "        vel, acc = self.update(pos[i], acc[i], gradient)\n",
        "        pos[i]  += vel\n",
        "        acc[i]   = acc\n",
        "    return self.average(pos, loss)"
      ],
      "metadata": {
        "id": "BOHgnO8ib_3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}