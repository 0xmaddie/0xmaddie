You know how you need to sample a language model a bunch of times to
get good responses? This is a wrapper class around the transformers
implementation of Llama 3 with some methods for "map/reduce" across
many Llama outputs.
